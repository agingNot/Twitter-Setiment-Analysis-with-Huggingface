{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Covid19 Twitter Sentiment Analysis with Hugging Face**","metadata":{"editable":false}},{"cell_type":"markdown","source":"Hugging Face is a platform that provides open-source machine learning technologies. You can install their package to access pre-built models, which you can use directly or fine-tune using your own dataset and leveraging prior knowledge gained from the initial training. Once trained, you can host your models on the platform and use them on other devices and applications in the future. To access all the features of the platform, please visit the website and sign in. To learn more about text classification with Hugging Face, please refer to the relevant resources.\n\nPlease note that Hugging Face models are based on deep learning and require significant GPU computational power for training. We recommend using Colab, your preferred GPU cloud provider, or a local machine with an NVIDIA GPU for this purpose.","metadata":{"editable":false}},{"cell_type":"markdown","source":"**Application of Hugging Face Text classification model Fune-tuning**","metadata":{"editable":false}},{"cell_type":"code","source":"!pip install datasets","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:11:33.924378Z","iopub.execute_input":"2023-05-15T03:11:33.924780Z","iopub.status.idle":"2023-05-15T03:11:45.527084Z","shell.execute_reply.started":"2023-05-15T03:11:33.924748Z","shell.execute_reply":"2023-05-15T03:11:45.525875Z"},"editable":false,"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.28.2)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.13.4)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (10.0.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.4.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (1.5.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.64.1)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (22.2.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (2.1.1)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.8.2)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.11.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:11:56.667127Z","iopub.execute_input":"2023-05-15T03:11:56.667491Z","iopub.status.idle":"2023-05-15T03:12:08.619172Z","shell.execute_reply.started":"2023-05-15T03:11:56.667459Z","shell.execute_reply":"2023-05-15T03:12:08.617822Z"},"editable":false,"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.28.1)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.11.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.3.23)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install sentencepiece","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:12:08.622767Z","iopub.execute_input":"2023-05-15T03:12:08.623225Z","iopub.status.idle":"2023-05-15T03:12:20.359655Z","shell.execute_reply.started":"2023-05-15T03:12:08.623180Z","shell.execute_reply":"2023-05-15T03:12:20.358376Z"},"editable":false,"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.98)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"**Importing Relevant Libraries**","metadata":{"editable":false}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom datasets import load_dataset\nfrom sklearn.model_selection import train_test_split\n\nfrom transformers import AutoModelForSequenceClassification\n# from transformers import TFAutoModelForSequenceClassification\n# from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n# from transformers import BertTokenizer, BertModel\nfrom transformers import AutoTokenizer, AutoConfig, AdamW\nfrom transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n\nfrom sklearn.metrics import mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:12:20.363706Z","iopub.execute_input":"2023-05-15T03:12:20.364405Z","iopub.status.idle":"2023-05-15T03:12:20.371136Z","shell.execute_reply.started":"2023-05-15T03:12:20.364371Z","shell.execute_reply":"2023-05-15T03:12:20.370114Z"},"editable":false,"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Disabe W&B\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:12:20.372485Z","iopub.execute_input":"2023-05-15T03:12:20.373843Z","iopub.status.idle":"2023-05-15T03:12:20.380433Z","shell.execute_reply.started":"2023-05-15T03:12:20.373808Z","shell.execute_reply":"2023-05-15T03:12:20.379619Z"},"editable":false,"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Load the dataset from a GitHub link\nurl = \"https://raw.githubusercontent.com/Azubi-Africa/Career_Accelerator_P5-NLP/master/zindi_challenge/data/Train.csv\"\ndf = pd.read_csv(url), encoding = \"ISO-8859-1\")\n\n\n# A way to eliminate rows containing NaN values\ndf = df[~df.isna().any(axis=1)]","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:12:23.975094Z","iopub.execute_input":"2023-05-15T03:12:23.975497Z","iopub.status.idle":"2023-05-15T03:12:23.985230Z","shell.execute_reply.started":"2023-05-15T03:12:23.975462Z","shell.execute_reply":"2023-05-15T03:12:23.982639Z"},"editable":false,"trusted":true},"execution_count":33,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[33], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    df = pd.read_csv(url), encoding = \"ISO-8859-1\")\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"],"ename":"SyntaxError","evalue":"unmatched ')' (506664577.py, line 3)","output_type":"error"}]},{"cell_type":"code","source":"# Load the dataset from a GitHub link\nimport pandas as pd\nurl = \"https://raw.githubusercontent.com/Azubi-Africa/Career_Accelerator_P5-NLP/master/zindi_challenge/data/Train.csv\"\ndf = pd.read_csv(url, encoding=\"ISO-8859-1\")\n\n\n# A way to eliminate rows containing NaN values\ndf = df[~df.isna().any(axis=1)]","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:14:46.098493Z","iopub.execute_input":"2023-05-15T03:14:46.099239Z","iopub.status.idle":"2023-05-15T03:14:46.250114Z","shell.execute_reply.started":"2023-05-15T03:14:46.099204Z","shell.execute_reply":"2023-05-15T03:14:46.249165Z"},"editable":false,"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"****Splitting the dataset in to Train & Eval****","metadata":{"editable":false}},{"cell_type":"code","source":"# Split the train data => {train, eval}\ntrain, eval = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:14:49.690645Z","iopub.execute_input":"2023-05-15T03:14:49.691336Z","iopub.status.idle":"2023-05-15T03:14:49.706304Z","shell.execute_reply.started":"2023-05-15T03:14:49.691300Z","shell.execute_reply":"2023-05-15T03:14:49.705169Z"},"editable":false,"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:14:54.792146Z","iopub.execute_input":"2023-05-15T03:14:54.792742Z","iopub.status.idle":"2023-05-15T03:14:54.808137Z","shell.execute_reply.started":"2023-05-15T03:14:54.792706Z","shell.execute_reply":"2023-05-15T03:14:54.806838Z"},"editable":false,"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"      tweet_id                                          safe_text  label  \\\n9305  YMRMEDME      Mickey's Measles has gone international <url>    0.0   \n3907  5GV8NEZS  S1256 [NEW] Extends exemption from charitable ...    0.0   \n795   EI10PS46  <user>  your ignorance on vaccines isn't just ...    1.0   \n5793  OM26E6DG  Pakistan partly suspends polio vaccination pro...    0.0   \n3431  NBBY86FX           In other news I've gone up like 1000 mmr    0.0   \n\n      agreement  \n9305   1.000000  \n3907   1.000000  \n795    0.666667  \n5793   1.000000  \n3431   1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>safe_text</th>\n      <th>label</th>\n      <th>agreement</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9305</th>\n      <td>YMRMEDME</td>\n      <td>Mickey's Measles has gone international &lt;url&gt;</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>3907</th>\n      <td>5GV8NEZS</td>\n      <td>S1256 [NEW] Extends exemption from charitable ...</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>795</th>\n      <td>EI10PS46</td>\n      <td>&lt;user&gt;  your ignorance on vaccines isn't just ...</td>\n      <td>1.0</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>5793</th>\n      <td>OM26E6DG</td>\n      <td>Pakistan partly suspends polio vaccination pro...</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>3431</th>\n      <td>NBBY86FX</td>\n      <td>In other news I've gone up like 1000 mmr</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:14:57.820263Z","iopub.execute_input":"2023-05-15T03:14:57.820647Z","iopub.status.idle":"2023-05-15T03:14:57.839701Z","shell.execute_reply.started":"2023-05-15T03:14:57.820614Z","shell.execute_reply":"2023-05-15T03:14:57.838733Z"},"editable":false,"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 7999 entries, 9305 to 1387\nData columns (total 4 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   tweet_id   7999 non-null   object \n 1   safe_text  7999 non-null   object \n 2   label      7999 non-null   float64\n 3   agreement  7999 non-null   float64\ndtypes: float64(2), object(2)\nmemory usage: 312.5+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"train.describe().T","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:15:00.521281Z","iopub.execute_input":"2023-05-15T03:15:00.521681Z","iopub.status.idle":"2023-05-15T03:15:00.546559Z","shell.execute_reply.started":"2023-05-15T03:15:00.521647Z","shell.execute_reply":"2023-05-15T03:15:00.545560Z"},"editable":false,"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"            count      mean       std       min       25%  50%  75%  max\nlabel      7999.0  0.301413  0.646832 -1.000000  0.000000  0.0  1.0  1.0\nagreement  7999.0  0.854398  0.180677  0.333333  0.666667  1.0  1.0  1.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>label</th>\n      <td>7999.0</td>\n      <td>0.301413</td>\n      <td>0.646832</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>agreement</th>\n      <td>7999.0</td>\n      <td>0.854398</td>\n      <td>0.180677</td>\n      <td>0.333333</td>\n      <td>0.666667</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"eval.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:15:03.399923Z","iopub.execute_input":"2023-05-15T03:15:03.400304Z","iopub.status.idle":"2023-05-15T03:15:03.415093Z","shell.execute_reply.started":"2023-05-15T03:15:03.400274Z","shell.execute_reply":"2023-05-15T03:15:03.414083Z"},"editable":false,"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"      tweet_id                                          safe_text  label  \\\n6571  R7JPIFN7  Children's Museum of Houston to Offer Free Vac...    1.0   \n1754  2DD250VN  <user> no. I was properly immunized prior to t...    1.0   \n3325  ESEVBTFN  <user> thx for posting vaccinations are impera...    1.0   \n1485  S17ZU0LC  This Baby Is Exactly Why Everyone Needs To Vac...    1.0   \n4175  IIN5D33V  Meeting tonight, 8:30pm in room 322 of the stu...    1.0   \n\n      agreement  \n6571   1.000000  \n1754   1.000000  \n3325   1.000000  \n1485   0.666667  \n4175   1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>safe_text</th>\n      <th>label</th>\n      <th>agreement</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6571</th>\n      <td>R7JPIFN7</td>\n      <td>Children's Museum of Houston to Offer Free Vac...</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1754</th>\n      <td>2DD250VN</td>\n      <td>&lt;user&gt; no. I was properly immunized prior to t...</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>3325</th>\n      <td>ESEVBTFN</td>\n      <td>&lt;user&gt; thx for posting vaccinations are impera...</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1485</th>\n      <td>S17ZU0LC</td>\n      <td>This Baby Is Exactly Why Everyone Needs To Vac...</td>\n      <td>1.0</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>4175</th>\n      <td>IIN5D33V</td>\n      <td>Meeting tonight, 8:30pm in room 322 of the stu...</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"eval.label.unique()","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:15:06.225457Z","iopub.execute_input":"2023-05-15T03:15:06.225887Z","iopub.status.idle":"2023-05-15T03:15:06.236050Z","shell.execute_reply.started":"2023-05-15T03:15:06.225855Z","shell.execute_reply":"2023-05-15T03:15:06.234622Z"},"editable":false,"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"array([ 1., -1.,  0.])"},"metadata":{}}]},{"cell_type":"code","source":"print(f\"new dataframe shapes: train is {train.shape}, eval is {eval.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:15:10.958753Z","iopub.execute_input":"2023-05-15T03:15:10.959116Z","iopub.status.idle":"2023-05-15T03:15:10.966247Z","shell.execute_reply.started":"2023-05-15T03:15:10.959087Z","shell.execute_reply":"2023-05-15T03:15:10.963549Z"},"editable":false,"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"new dataframe shapes: train is (7999, 4), eval is (2000, 4)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"****Creating a pytorch dataset****","metadata":{"editable":false}},{"cell_type":"code","source":"from datasets import DatasetDict, Dataset\ntrain_dataset = Dataset.from_pandas(train[['tweet_id', 'safe_text', 'label', 'agreement']])\neval_dataset = Dataset.from_pandas(eval[['tweet_id', 'safe_text', 'label', 'agreement']])\n\ndataset = DatasetDict({'train': train_dataset, 'eval': eval_dataset})\ndataset = dataset.remove_columns('__index_level_0__')\ndataset","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:15:13.905770Z","iopub.execute_input":"2023-05-15T03:15:13.906128Z","iopub.status.idle":"2023-05-15T03:15:13.934383Z","shell.execute_reply.started":"2023-05-15T03:15:13.906099Z","shell.execute_reply":"2023-05-15T03:15:13.933515Z"},"editable":false,"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['tweet_id', 'safe_text', 'label', 'agreement'],\n        num_rows: 7999\n    })\n    eval: Dataset({\n        features: ['tweet_id', 'safe_text', 'label', 'agreement'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"**Preprocessing our data**","metadata":{"editable":false}},{"cell_type":"code","source":"# Preprocess text (username and link placeholders)\ndef preprocess(text):\n    new_text = []\n    for t in text.split(\" \"):\n        t = '@user' if t.startswith('@') and len(t) > 1 else t\n        t = 'http' if t.startswith('http') else t\n        new_text.append(t)\n    return \" \".join(new_text)\n\n# checkpoint = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\ncheckpoint = \"roberta-base\"\n# checkpoint = \"xlnet-base-cased\"\n\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:15:18.028989Z","iopub.execute_input":"2023-05-15T03:15:18.029356Z","iopub.status.idle":"2023-05-15T03:15:18.620446Z","shell.execute_reply.started":"2023-05-15T03:15:18.029327Z","shell.execute_reply":"2023-05-15T03:15:18.619436Z"},"editable":false,"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def transform_labels(label):\n\n    label = label['label']\n    num = 0\n    if label == -1: #'Negative'\n        num = 0\n    elif label == 0: #'Neutral'\n        num = 1\n    elif label == 1: #'Positive'\n        num = 2\n\n    return {'labels': num}\n\ndef tokenize_data(example):\n    return tokenizer(example['safe_text'], padding='max_length')\n\n# Change the tweets to tokens that the models can exploit\ndataset = dataset.map(tokenize_data, batched=True)\n\n# Transform\tlabels and remove the useless columns\nremove_columns = ['tweet_id', 'label', 'safe_text', 'agreement']\ndataset = dataset.map(transform_labels, remove_columns=remove_columns)\n# data_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:15:22.863446Z","iopub.execute_input":"2023-05-15T03:15:22.864438Z","iopub.status.idle":"2023-05-15T03:15:36.000619Z","shell.execute_reply.started":"2023-05-15T03:15:22.864388Z","shell.execute_reply":"2023-05-15T03:15:35.999621Z"},"editable":false,"trusted":true},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70012142a16f499c915dc65f4c64c554"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fa43558a07e43359b5c86d392b17770"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7999 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0330a4646e2842238375341ae185ec22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2000 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19fb8a9eda9f4f6ea2454de9cb4f5e4c"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:15:38.019670Z","iopub.execute_input":"2023-05-15T03:15:38.020083Z","iopub.status.idle":"2023-05-15T03:15:38.035351Z","shell.execute_reply.started":"2023-05-15T03:15:38.020048Z","shell.execute_reply":"2023-05-15T03:15:38.034207Z"},"editable":false,"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 7999\n    })\n    eval: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# Configure the trianing parameters like `num_train_epochs`: \n# the number of time the model will repeat the training loop over the dataset\ntraining_args = TrainingArguments(\n    \"test_trainer\",\n    num_train_epochs=10,\n    load_best_model_at_end=True,\n    save_strategy='epoch',\n    evaluation_strategy='epoch',\n    logging_strategy='epoch',\n    logging_steps=100,\n    per_device_train_batch_size=16,\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:15:41.825836Z","iopub.execute_input":"2023-05-15T03:15:41.826192Z","iopub.status.idle":"2023-05-15T03:15:41.836091Z","shell.execute_reply.started":"2023-05-15T03:15:41.826158Z","shell.execute_reply":"2023-05-15T03:15:41.835070Z"},"editable":false,"trusted":true},"execution_count":48,"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}]},{"cell_type":"code","source":"# Loading a pretrain model while specifying the number of labels in our dataset for fine-tuning\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:15:49.039903Z","iopub.execute_input":"2023-05-15T03:15:49.042095Z","iopub.status.idle":"2023-05-15T03:15:51.277355Z","shell.execute_reply.started":"2023-05-15T03:15:49.042047Z","shell.execute_reply":"2023-05-15T03:15:51.276494Z"},"editable":false,"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# set up the optimizer with the PyTorch implementation of AdamW\n# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:03:21.461993Z","iopub.execute_input":"2023-05-15T03:03:21.462398Z","iopub.status.idle":"2023-05-15T03:03:21.467513Z","shell.execute_reply.started":"2023-05-15T03:03:21.462363Z","shell.execute_reply":"2023-05-15T03:03:21.466674Z"},"editable":false,"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_dataset = dataset['train'].shuffle(seed=24) \neval_dataset = dataset['eval'].shuffle(seed=24) ","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:16:03.502292Z","iopub.execute_input":"2023-05-15T03:16:03.502735Z","iopub.status.idle":"2023-05-15T03:16:03.520269Z","shell.execute_reply.started":"2023-05-15T03:16:03.502701Z","shell.execute_reply":"2023-05-15T03:16:03.519082Z"},"editable":false,"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return {\"rmse\": mean_squared_error(labels, predictions, squared=False)}","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:16:10.028212Z","iopub.execute_input":"2023-05-15T03:16:10.028819Z","iopub.status.idle":"2023-05-15T03:16:10.035830Z","shell.execute_reply.started":"2023-05-15T03:16:10.028785Z","shell.execute_reply":"2023-05-15T03:16:10.034285Z"},"editable":false,"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    training_args, \n    train_dataset=train_dataset, \n    eval_dataset=eval_dataset,\n    # data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:16:12.900971Z","iopub.execute_input":"2023-05-15T03:16:12.901318Z","iopub.status.idle":"2023-05-15T03:16:13.057803Z","shell.execute_reply.started":"2023-05-15T03:16:12.901288Z","shell.execute_reply":"2023-05-15T03:16:13.056854Z"},"editable":false,"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-05-15T03:16:18.916142Z","iopub.execute_input":"2023-05-15T03:16:18.916661Z","iopub.status.idle":"2023-05-15T04:31:51.968577Z","shell.execute_reply.started":"2023-05-15T03:16:18.916619Z","shell.execute_reply":"2023-05-15T04:31:51.967486Z"},"editable":false,"trusted":true},"execution_count":53,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\nYou're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2500/2500 1:15:26, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rmse</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.742800</td>\n      <td>0.705610</td>\n      <td>0.767789</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.601800</td>\n      <td>0.587418</td>\n      <td>0.663702</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.463800</td>\n      <td>0.616905</td>\n      <td>0.632060</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.336300</td>\n      <td>0.596771</td>\n      <td>0.597913</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.237600</td>\n      <td>0.776491</td>\n      <td>0.604979</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.171000</td>\n      <td>0.883687</td>\n      <td>0.607042</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.123900</td>\n      <td>1.013598</td>\n      <td>0.614817</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.093800</td>\n      <td>1.080369</td>\n      <td>0.605392</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.072900</td>\n      <td>1.255414</td>\n      <td>0.630079</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.057400</td>\n      <td>1.288336</td>\n      <td>0.629285</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2500, training_loss=0.29012388076782225, metrics={'train_runtime': 4533.0274, 'train_samples_per_second': 17.646, 'train_steps_per_second': 0.552, 'total_flos': 2.104644228406272e+16, 'train_loss': 0.29012388076782225, 'epoch': 10.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Launch the final evaluation \ntrainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2023-05-15T04:39:18.539954Z","iopub.execute_input":"2023-05-15T04:39:18.540429Z","iopub.status.idle":"2023-05-15T04:40:00.605007Z","shell.execute_reply.started":"2023-05-15T04:39:18.540397Z","shell.execute_reply":"2023-05-15T04:40:00.604125Z"},"editable":false,"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:41]\n    </div>\n    "},"metadata":{}},{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.5874180793762207,\n 'eval_rmse': 0.6637017402418047,\n 'eval_runtime': 42.0346,\n 'eval_samples_per_second': 47.58,\n 'eval_steps_per_second': 2.974,\n 'epoch': 10.0}"},"metadata":{}}]},{"cell_type":"markdown","source":"**Pushing to HuggingFace**","metadata":{"editable":false}},{"cell_type":"code","source":"# # Push the model and tokenizer to Hugging Face\ntoken = \"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\"\nmodel.push_to_hub(\"ikoghoemmanuell/finetuned_sentiment_model\", use_auth_token=token, commit_message=\"Pushed model\")\ntokenizer.push_to_hub(\"https://huggingface.co/TruelyEpic/tweeter-sentiment-analysis-bert-base-cased\", use_auth_token=token, commit_message=\"pushed tokenize","metadata":{"execution":{"iopub.status.busy":"2023-05-15T04:40:57.367126Z","iopub.execute_input":"2023-05-15T04:40:57.367491Z","iopub.status.idle":"2023-05-15T04:40:57.376328Z","shell.execute_reply.started":"2023-05-15T04:40:57.367461Z","shell.execute_reply":"2023-05-15T04:40:57.375002Z"},"editable":false,"trusted":true},"execution_count":55,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[55], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    token = \"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\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"],"ename":"IndentationError","evalue":"unexpected indent (3635035780.py, line 2)","output_type":"error"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n\nmodel_path = \"TruelyEpic/tweeter-sentiment-analysis-bert-base-cased\"\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nconfig = AutoConfig.from_pretrained(model_path)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"token = \"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\"\nmodel_id = \"TruelyEpic/tweeter-sentiment-analysis-bert-base-cased\"\ntokenizer_id = \"TruelyEpic/tweeter-sentiment-analysis-bert-base-cased\"\n\n# Push the model\n!huggingface-cli push finetuned_sentiment_model $model_id --use-deepspeed --token $token --hub-model\n\n# Push the tokenizer\n!huggingface-cli push tweeter-sentiment-analysis-bert-base-cased $tokenizer_id --use-deepspeed --token $token --hub-model\n","metadata":{"execution":{"iopub.status.busy":"2023-05-15T04:59:00.291301Z","iopub.execute_input":"2023-05-15T04:59:00.291749Z","iopub.status.idle":"2023-05-15T04:59:03.114249Z","shell.execute_reply.started":"2023-05-15T04:59:00.291713Z","shell.execute_reply":"2023-05-15T04:59:03.113061Z"},"editable":false,"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nusage: huggingface-cli <command> [<args>]\nhuggingface-cli: error: argument {env,login,whoami,logout,repo,lfs-enable-largefiles,lfs-multipart-upload,scan-cache,delete-cache}: invalid choice: 'push' (choose from 'env', 'login', 'whoami', 'logout', 'repo', 'lfs-enable-largefiles', 'lfs-multipart-upload', 'scan-cache', 'delete-cache')\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nusage: huggingface-cli <command> [<args>]\nhuggingface-cli: error: argument {env,login,whoami,logout,repo,lfs-enable-largefiles,lfs-multipart-upload,scan-cache,delete-cache}: invalid choice: 'push' (choose from 'env', 'login', 'whoami', 'logout', 'repo', 'lfs-enable-largefiles', 'lfs-multipart-upload', 'scan-cache', 'delete-cache')\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification\n\n# Load the pre-trained model and tokenizer\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-cased\")","metadata":{"execution":{"iopub.status.busy":"2023-05-15T05:16:31.274147Z","iopub.execute_input":"2023-05-15T05:16:31.274559Z","iopub.status.idle":"2023-05-15T05:16:33.269360Z","shell.execute_reply.started":"2023-05-15T05:16:31.274526Z","shell.execute_reply":"2023-05-15T05:16:33.268412Z"},"editable":false,"trusted":true},"execution_count":63,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the model and tokenizer\nmodel.save_pretrained(\"model/\")\ntokenizer.save_pretrained(\"tokenizer/\")","metadata":{"execution":{"iopub.status.busy":"2023-05-15T05:16:41.016068Z","iopub.execute_input":"2023-05-15T05:16:41.016442Z","iopub.status.idle":"2023-05-15T05:16:41.956002Z","shell.execute_reply.started":"2023-05-15T05:16:41.016411Z","shell.execute_reply":"2023-05-15T05:16:41.955069Z"},"editable":false,"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"('tokenizer/tokenizer_config.json',\n 'tokenizer/special_tokens_map.json',\n 'tokenizer/vocab.txt',\n 'tokenizer/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"import json","metadata":{"execution":{"iopub.status.busy":"2023-05-15T05:16:58.538400Z","iopub.execute_input":"2023-05-15T05:16:58.538777Z","iopub.status.idle":"2023-05-15T05:16:58.542932Z","shell.execute_reply.started":"2023-05-15T05:16:58.538748Z","shell.execute_reply":"2023-05-15T05:16:58.541887Z"},"editable":false,"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# Get the tokenizer vocabulary and save it as a JSON file\ntokenizer_vocab = tokenizer.get_vocab()\nwith open(\"tokenizer/tokenizer.json\", \"w\") as f:\n    json.dump(tokenizer_vocab, f)","metadata":{"execution":{"iopub.status.busy":"2023-05-15T05:17:04.351193Z","iopub.execute_input":"2023-05-15T05:17:04.351594Z","iopub.status.idle":"2023-05-15T05:17:04.424298Z","shell.execute_reply.started":"2023-05-15T05:17:04.351542Z","shell.execute_reply":"2023-05-15T05:17:04.423156Z"},"editable":false,"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"pip install streamlit","metadata":{"execution":{"iopub.status.busy":"2023-05-15T05:24:31.081769Z","iopub.execute_input":"2023-05-15T05:24:31.082142Z","iopub.status.idle":"2023-05-15T05:24:47.214266Z","shell.execute_reply.started":"2023-05-15T05:24:31.082112Z","shell.execute_reply":"2023-05-15T05:24:47.212946Z"},"editable":false,"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCollecting streamlit\n  Downloading streamlit-1.22.0-py2.py3-none-any.whl (8.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.5.0)\nCollecting validators>=0.2\n  Downloading validators-0.20.0.tar.gz (30 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.8.2)\nRequirement already satisfied: gitpython!=3.1.19 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.1.31)\nRequirement already satisfied: importlib-metadata>=1.4 in /opt/conda/lib/python3.10/site-packages (from streamlit) (6.0.1)\nRequirement already satisfied: tornado>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (6.2)\nRequirement already satisfied: altair<5,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.2.2)\nCollecting pydeck>=0.1.dev5\n  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.1.3)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (13.3.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (9.5.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.23.5)\nRequirement already satisfied: pandas<3,>=0.25 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.5.3)\nRequirement already satisfied: tzlocal>=1.1 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.3)\nRequirement already satisfied: packaging>=14.1 in /opt/conda/lib/python3.10/site-packages (from streamlit) (21.3)\nCollecting watchdog\n  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: protobuf<4,>=3.12 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.20.3)\nRequirement already satisfied: pyarrow>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (10.0.1)\nRequirement already satisfied: cachetools>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (5.3.0)\nRequirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from streamlit) (0.10.2)\nRequirement already satisfied: requests>=2.4 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.28.2)\nCollecting blinker>=1.0.0\n  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\nRequirement already satisfied: tenacity<9,>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.2.2)\nRequirement already satisfied: pympler>=0.9 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.0.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from altair<5,>=3.2.0->streamlit) (3.1.2)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<5,>=3.2.0->streamlit) (4.17.3)\nRequirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from altair<5,>=3.2.0->streamlit) (0.4)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<5,>=3.2.0->streamlit) (0.12.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.19->streamlit) (4.0.10)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=1.4->streamlit) (3.15.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=14.1->streamlit) (3.0.9)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=0.25->streamlit) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil->streamlit) (1.16.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.4->streamlit) (1.26.15)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.4->streamlit) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.4->streamlit) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.4->streamlit) (2.1.1)\nRequirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->streamlit) (2.2.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->streamlit) (2.15.0)\nRequirement already satisfied: pytz-deprecation-shim in /opt/conda/lib/python3.10/site-packages (from tzlocal>=1.1->streamlit) (0.1.0.post0)\nRequirement already satisfied: decorator>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from validators>=0.2->streamlit) (5.1.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit) (5.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->altair<5,>=3.2.0->streamlit) (2.1.2)\nRequirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit) (22.2.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit) (0.19.3)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->streamlit) (0.1.2)\nRequirement already satisfied: tzdata in /opt/conda/lib/python3.10/site-packages (from pytz-deprecation-shim->tzlocal>=1.1->streamlit) (2023.3)\nBuilding wheels for collected packages: validators\n  Building wheel for validators (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19581 sha256=caeaac74e7e53ede67c5cec588efb121f1ecab55fe6ef09707492877a8690a85\n  Stored in directory: /root/.cache/pip/wheels/f2/ed/dd/d3a556ad245ef9dc570c6bcd2f22886d17b0b408dd3bbb9ac3\nSuccessfully built validators\nInstalling collected packages: watchdog, validators, blinker, pydeck, streamlit\nSuccessfully installed blinker-1.6.2 pydeck-0.8.1b0 streamlit-1.22.0 validators-0.20.0 watchdog-3.0.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install gradio","metadata":{"execution":{"iopub.status.busy":"2023-05-15T05:44:47.538396Z","iopub.execute_input":"2023-05-15T05:44:47.538769Z","iopub.status.idle":"2023-05-15T05:45:04.012351Z","shell.execute_reply.started":"2023-05-15T05:44:47.538738Z","shell.execute_reply":"2023-05-15T05:45:04.010965Z"},"editable":false,"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCollecting gradio\n  Downloading gradio-3.30.0-py3-none-any.whl (17.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting ffmpy\n  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: altair>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.2.2)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.1.2)\nRequirement already satisfied: pygments>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.15.0)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from gradio) (3.6.3)\nCollecting python-multipart\n  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from gradio) (1.23.5)\nRequirement already satisfied: aiofiles in /opt/conda/lib/python3.10/site-packages (from gradio) (22.1.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from gradio) (1.5.3)\nRequirement already satisfied: markupsafe in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.2)\nRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio) (0.95.0)\nCollecting gradio-client>=0.2.4\n  Downloading gradio_client-0.2.4-py3-none-any.whl (287 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.9/287.9 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting semantic-version\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nCollecting mdit-py-plugins<=0.3.3\n  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from gradio) (3.8.4)\nRequirement already satisfied: websockets>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (11.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from gradio) (2.28.2)\nRequirement already satisfied: huggingface-hub>=0.13.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.13.4)\nRequirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from gradio) (1.10.7)\nRequirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.21.1)\nRequirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.2.0)\nCollecting httpx\n  Downloading httpx-0.24.0-py3-none-any.whl (75 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from gradio) (9.5.0)\nRequirement already satisfied: orjson in /opt/conda/lib/python3.10/site-packages (from gradio) (3.8.10)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from gradio) (6.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from gradio) (4.5.0)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair>=4.2.0->gradio) (0.12.0)\nRequirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from altair>=4.2.0->gradio) (0.4)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair>=4.2.0->gradio) (4.17.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gradio-client>=0.2.4->gradio) (21.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client>=0.2.4->gradio) (2023.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.13.0->gradio) (3.11.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.13.0->gradio) (4.64.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\nCollecting linkify-it-py<3,>=1\n  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->gradio) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->gradio) (2023.3)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\nRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (8.1.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio) (4.0.2)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio) (1.8.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio) (1.3.3)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio) (2.1.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio) (22.2.0)\nRequirement already satisfied: starlette<0.27.0,>=0.26.1 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio) (0.26.1)\nCollecting httpcore<0.18.0,>=0.15.0\n  Downloading httpcore-0.17.0-py3-none-any.whl (70 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx->gradio) (3.4)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->gradio) (1.3.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx->gradio) (2022.12.7)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio) (3.0.9)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio) (4.39.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio) (1.0.7)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio) (1.4.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->gradio) (1.26.15)\nRequirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.6.2)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\nCollecting uc-micro-py\n  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\nBuilding wheels for collected packages: ffmpy\n  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4712 sha256=1482e72a77a0e1239512911886b63c800ec6cc3f5c4a6f54d9bb53cbaa4d3344\n  Stored in directory: /root/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\nSuccessfully built ffmpy\nInstalling collected packages: ffmpy, uc-micro-py, semantic-version, python-multipart, mdit-py-plugins, linkify-it-py, httpcore, httpx, gradio-client, gradio\n  Attempting uninstall: mdit-py-plugins\n    Found existing installation: mdit-py-plugins 0.3.5\n    Uninstalling mdit-py-plugins-0.3.5:\n      Successfully uninstalled mdit-py-plugins-0.3.5\nSuccessfully installed ffmpy-0.3.0 gradio-3.30.0 gradio-client-0.2.4 httpcore-0.17.0 httpx-0.24.0 linkify-it-py-2.0.2 mdit-py-plugins-0.3.3 python-multipart-0.0.6 semantic-version-2.10.0 uc-micro-py-1.0.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import streamlit as st\nimport transformers\nimport torch\n\n# Load the model and tokenizer\nmodel = transformers.AutoModelForSequenceClassification.from_pretrained(\"BertTokenizer.from_pretrained(\"bert-base-cased\")\")\ntokenizer = transformers.AutoTokenizer.from_pretrained(\"BertTokenizer.from_pretrained(\"bert-base-cased\")\")\n\n# Define the function for sentiment analysis\n@st.cache(allow_output_mutation=True)\ndef predict_sentiment(text):\n    # Tokenize the input text\n    inputs = tokenizer(text, return_tensors=\"pt\")\n    # Pass the tokenized input through the model\n    outputs = model(**inputs)\n    # Get the predicted class and return the corresponding sentiment\n    predicted_class = torch.argmax(outputs.logits, dim=-1).item()\n    if predicted_class == 0:\n        return \"Negative\"\n    elif predicted_class == 1:\n        return \"Neutral\"\n    else:\n        return \"Positive\"\n\n# Setting the page configurations\nst.set_page_config(\n    page_title=\"Sentiment Analysis App\",\n    page_icon=\":smile:\",\n    layout=\"wide\",\n    initial_sidebar_state=\"auto\",\n)\n\n# Add description and title\nst.write(\"\"\"\n# How Positive or Negative is your Text?\nEnter some text and we'll tell you if it has a positive, negative, or neutral sentiment!\n\"\"\")\n\n\n# Add image\nimage = st.image(\"https://i0.wp.com/thedatascientist.com/wp-content/uploads/2018/10/sentiment-analysis.png\", width=400)\n\n# Get user input\ntext = st.text_input(\"Enter some text here:\")\n\n# Define the CSS style for the app\nst.markdown(\n\"\"\"\n<style>\nbody {\n    background-color: #f5f5f5;\n}\nh1 {\n    color: #4e79a7;\n}\n</style>\n\"\"\",\nunsafe_allow_html=True\n)\n\n\n# Show sentiment output\nif text:\n    sentiment = predict_sentiment(text)\n    if sentiment == \"Positive\":\n        st.success(f\"The sentiment is {sentiment}!\")\n    elif sentiment == \"Negative\":\n        st.error(f\"The sentiment is {sentiment}.\")\n    else:\n        st.warning(f\"The sentiment is {sentiment}.\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-15T05:45:05.526423Z","iopub.execute_input":"2023-05-15T05:45:05.527653Z","iopub.status.idle":"2023-05-15T05:45:05.539895Z","shell.execute_reply.started":"2023-05-15T05:45:05.527595Z","shell.execute_reply":"2023-05-15T05:45:05.538291Z"},"editable":false,"trusted":true},"execution_count":77,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[77], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    model = transformers.AutoModelForSequenceClassification.from_pretrained(\"BertTokenizer.from_pretrained(\"bert-base-cased\")\")\u001b[0m\n\u001b[0m                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"],"ename":"SyntaxError","evalue":"invalid syntax. Perhaps you forgot a comma? (1724802585.py, line 6)","output_type":"error"}]},{"cell_type":"code","source":"import transformers\nimport torch\nimport gradio as gr\n\n# Load the model and tokenizer\nmodel = transformers.AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\")\ntokenizer = transformers.AutoTokenizer.from_pretrained(\"bert-base-cased\")\n\n# Define the function for sentiment analysis\ndef predict_sentiment(text):\n    # Tokenize the input text\n    inputs = tokenizer(text, return_tensors=\"pt\")\n    # Pass the tokenized input through the model\n    outputs = model(**inputs)\n    # Get the predicted class and return the corresponding sentiment\n    predicted_class = torch.argmax(outputs.logits, dim=-1).item()\n    if predicted_class == 0:\n        return \"Negative\"\n    elif predicted_class == 1:\n        return \"Neutral\"\n    else:\n        return \"Positive\"\n\n# Create the input and output interfaces\ninputs = gr.inputs.Textbox(label=\"Enter some text here:\")\noutputs = gr.outputs.Textbox(label=\"Sentiment\")\n\n# Create the Gradio interface\ngr.Interface(fn=predict_sentiment, inputs=inputs, outputs=outputs,\n             title=\"Sentiment Analysis App\",\n             description=\"Enter some text and we'll tell you if it has a positive, negative, or neutral sentiment!\",\n             article=\"https://huggingface.co/transformers/model_doc/bert.html\",\n             thumbnail=\"https://i0.wp.com/thedatascientist.com/wp-content/uploads/2018/10/sentiment-analysis.png\").launch()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-15T05:45:18.975130Z","iopub.execute_input":"2023-05-15T05:45:18.975672Z","iopub.status.idle":"2023-05-15T05:45:36.728167Z","shell.execute_reply.started":"2023-05-15T05:45:18.975635Z","shell.execute_reply":"2023-05-15T05:45:36.727053Z"},"editable":false,"trusted":true},"execution_count":78,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c7f8431070847749c6e45e044a4ad5c"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n  warnings.warn(value)\n/opt/conda/lib/python3.10/site-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n  warnings.warn(value)\n/opt/conda/lib/python3.10/site-packages/gradio/outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Kaggle notebooks require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\nRunning on local URL:  http://127.0.0.1:7860\nRunning on public URL: https://03c25871b30a970dd7.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://03c25871b30a970dd7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":78,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}]},{"cell_type":"code","source":"import gradio as gr\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\nimport torch","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\")\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_sentiment(text):\n    inputs = tokenizer(text, return_tensors=\"pt\")\n    outputs = model(**inputs)\n    predicted_class = torch.argmax(outputs.logits, dim=-1).item()\n    if predicted_class == 0:\n        return \"Negative\"\n    elif predicted_class == 1:\n        return \"Neutral\"\n    else:\n        return \"Positive\"","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input = gr.inputs.Textbox(label=\"Enter some text here:\")\noutputs = gr.outputs.Textbox(label=\"Sentiment\")","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gr.Interface(fn=predict_sentiment, inputs=inputs, outputs=outputs,\n             title=\"Sentiment Analysis App\",\n             description=\"Enter some text and we'll tell you if it has a positive, negative, or neutral sentiment!\",\n             article=\"https://huggingface.co/transformers/model_doc/bert.html\",\n             thumbnail=\"https://i0.wp.com/thedatascientist.com/wp-content/uploads/2018/10/sentiment-analysis.png\").launch()\n","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformers-cli login\ntransformers-cli repo create your-repo-name\ntransformers-cli push your-repo-name","metadata":{"editable":false},"execution_count":null,"outputs":[]}]}